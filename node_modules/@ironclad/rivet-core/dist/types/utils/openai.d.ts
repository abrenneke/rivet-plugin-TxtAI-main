import { TiktokenModel } from '@dqbd/tiktoken';
export type OpenAIModel = {
    maxTokens: number;
    tiktokenModel: TiktokenModel;
    cost: {
        prompt: number;
        completion: number;
    };
    displayName: string;
};
export declare const openaiModels: {
    'gpt-4': {
        maxTokens: number;
        tiktokenModel: "gpt-4";
        cost: {
            prompt: number;
            completion: number;
        };
        displayName: string;
    };
    'gpt-4-32k': {
        maxTokens: number;
        tiktokenModel: "gpt-4-32k";
        cost: {
            prompt: number;
            completion: number;
        };
        displayName: string;
    };
    'gpt-4-0613': {
        maxTokens: number;
        tiktokenModel: "gpt-4";
        cost: {
            prompt: number;
            completion: number;
        };
        displayName: string;
    };
    'gpt-4-32k-0613': {
        maxTokens: number;
        tiktokenModel: "gpt-4";
        cost: {
            prompt: number;
            completion: number;
        };
        displayName: string;
    };
    'gpt-3.5-turbo': {
        maxTokens: number;
        tiktokenModel: "gpt-3.5-turbo";
        cost: {
            prompt: number;
            completion: number;
        };
        displayName: string;
    };
    'gpt-3.5-turbo-0613': {
        maxTokens: number;
        tiktokenModel: "gpt-3.5-turbo";
        cost: {
            prompt: number;
            completion: number;
        };
        displayName: string;
    };
    'gpt-3.5-turbo-16k-0613': {
        maxTokens: number;
        tiktokenModel: "gpt-3.5-turbo";
        cost: {
            prompt: number;
            completion: number;
        };
        displayName: string;
    };
};
export declare const openAiModelOptions: {
    value: string;
    label: string;
}[];
export declare class OpenAIError extends Error {
    readonly status: number;
    readonly responseJson: any;
    constructor(status: number, responseJson: any);
}
export type ChatCompletionRole = 'system' | 'assistant' | 'user' | 'function';
export type ChatCompletionRequestMessage = {
    role: ChatCompletionRole;
    /** The content of the message. */
    content: string;
    name: string | undefined;
    function_call: object | undefined;
};
export type ChatCompletionOptions = {
    endpoint: string;
    auth: {
        apiKey: string;
        organization?: string;
    };
    headers?: Record<string, string>;
    signal?: AbortSignal;
    model: string;
    messages: ChatCompletionRequestMessage[];
    temperature?: number;
    top_p?: number;
    max_tokens?: number;
    n?: number;
    stop?: string | string[];
    presence_penalty?: number;
    frequency_penalty?: number;
    logit_bias?: {
        [key: number]: number;
    };
    functions?: ChatCompletionFunction[];
};
export type ChatCompletionResponse = {
    id: string;
    object: 'text_completion';
    created: number;
    model: string;
    choices: ChatCompletionResponseChoice[];
};
export type ChatCompletionResponseMessage = {
    role: ChatCompletionRole;
    content: string;
    function_call?: object;
};
export type ChatCompletionResponseChoice = {
    index: number;
    finish_reason: 'stop' | 'length' | 'insufficient_tokens' | 'function_call';
    message: ChatCompletionResponseMessage;
};
export type ChatCompletionChunk = {
    object: 'chat.completion.chunk';
    created: number;
    model: string;
    choices?: ChatCompletionChunkChoice[];
};
export type GptFunctionCall = {
    name: string;
    arguments: string;
};
export type GptFunctionCallDelta = {
    name?: string;
    arguments?: string;
};
export type ChatCompletionChunkChoice = {
    index: number;
    message_index: number;
    delta: {
        role?: 'assistant';
        content?: string;
        function_call?: GptFunctionCallDelta;
    };
    finish_reason: null | 'stop' | 'length' | 'insufficient_tokens' | 'function_call';
};
export type ChatCompletionFunction = {
    name: string;
    description: string;
    parameters: object;
};
export declare const DEFAULT_CHAT_ENDPOINT = "https://api.openai.com/v1/chat/completions";
export declare function streamChatCompletions({ endpoint, auth, signal, headers, ...rest }: ChatCompletionOptions): AsyncGenerator<ChatCompletionChunk>;
