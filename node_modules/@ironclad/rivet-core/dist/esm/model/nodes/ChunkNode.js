import { NodeImpl, nodeDefinition } from '../../model/NodeImpl.js';
import { chunkStringByTokenCount } from '../../utils/tokenizer.js';
import { nanoid } from 'nanoid/non-secure';
import { coerceType } from '../../utils/coerceType.js';
import { dedent } from 'ts-dedent';
import { openAiModelOptions, openaiModels } from '../../utils/openai.js';
export class ChunkNodeImpl extends NodeImpl {
    static create() {
        const chartNode = {
            type: 'chunk',
            title: 'Chunk',
            id: nanoid(),
            visualData: {
                x: 0,
                y: 0,
                width: 200,
            },
            data: {
                model: 'gpt-3.5-turbo',
                useModelInput: false,
                numTokensPerChunk: 1024,
                overlap: 0,
            },
        };
        return chartNode;
    }
    getInputDefinitions() {
        return [
            {
                id: 'input',
                title: 'Input',
                dataType: 'string',
            },
        ];
    }
    getOutputDefinitions() {
        return [
            {
                id: 'chunks',
                title: 'Chunks',
                dataType: 'string[]',
            },
            {
                id: 'first',
                title: 'First',
                dataType: 'string',
            },
            {
                id: 'last',
                title: 'Last',
                dataType: 'string',
            },
            {
                id: 'indexes',
                title: 'Indexes',
                dataType: 'number[]',
            },
            {
                id: 'count',
                title: 'Count',
                dataType: 'number',
            },
        ];
    }
    getEditors() {
        return [
            {
                type: 'dropdown',
                label: 'Model',
                dataKey: 'model',
                options: openAiModelOptions,
                useInputToggleDataKey: 'useModelInput',
            },
            {
                type: 'number',
                label: 'Number of tokens per chunk',
                dataKey: 'numTokensPerChunk',
                min: 1,
                max: 32768,
                step: 1,
            },
            {
                type: 'number',
                label: 'Overlap (in %)',
                dataKey: 'overlap',
                min: 0,
                max: 100,
                step: 1,
            },
        ];
    }
    getBody() {
        return dedent `
      Model: ${this.data.model}
      Token Count: ${this.data.numTokensPerChunk.toLocaleString()}
      ${this.data.overlap ? `Overlap: ${this.data.overlap}%` : ''}
    `;
    }
    static getUIData() {
        return {
            infoBoxBody: dedent `
          Splits the input text into an array of chunks based on an approximate GPT token count per chunk.

          The "overlap" setting allows you to partially overlap the chunks for redundancy.

          Can also be used for string length truncation by only using the \`First\` or \`Last\` outputs of the node.
        `,
            infoBoxTitle: 'Chunk Node',
            contextMenuTitle: 'Chunk',
            group: ['Text'],
        };
    }
    async process(inputs) {
        const input = coerceType(inputs['input'], 'string');
        const overlapPercent = this.chartNode.data.overlap / 100;
        const chunked = chunkStringByTokenCount(input, this.chartNode.data.numTokensPerChunk, openaiModels[this.chartNode.data.model].tiktokenModel, overlapPercent);
        return {
            ['chunks']: {
                type: 'string[]',
                value: chunked,
            },
            ['first']: {
                type: 'string',
                value: chunked[0],
            },
            ['last']: {
                type: 'string',
                value: chunked.at(-1),
            },
            ['indexes']: {
                type: 'number[]',
                value: chunked.map((_, i) => i + 1),
            },
            ['count']: {
                type: 'number',
                value: chunked.length,
            },
        };
    }
}
export const chunkNode = nodeDefinition(ChunkNodeImpl, 'Chunk');
